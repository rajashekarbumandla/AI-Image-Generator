# generator.py

import os
import json
from datetime import datetime
from typing import List, Dict

import torch
from PIL import Image, ImageDraw, ImageFont

from prompt_utils import build_prompt, build_negative_prompt
from config import OUTPUT_DIR


def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)


def add_watermark(img: Image.Image, text: str = "AI-generated"):
    watermark_img = img.copy()
    draw = ImageDraw.Draw(watermark_img)

    font_size = max(img.width // 40, 14)

    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        font = ImageFont.load_default()

    # New way: calculate text size using textbbox instead of textsize
    bbox = draw.textbbox((0, 0), text, font=font)
    text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]

    margin = 10
    position = (img.width - text_w - margin, img.height - text_h - margin)

    draw.text(position, text, font=font, fill="white")

    return watermark_img



def generate_images(
    pipe,
    device: str,
    user_prompt: str,
    style: str,
    negative_prompt: str | None,
    num_images: int = 1,
    num_inference_steps: int = 30,
    guidance_scale: float = 7.5,
    output_dir: str = OUTPUT_DIR
) -> List[Dict]:
    ensure_dir(output_dir)

    full_prompt = build_prompt(user_prompt, style)
    negative = build_negative_prompt(negative_prompt)

    # Handle autocast differently on CPU/GPU
    if device == "cuda":
        ctx = torch.autocast(device_type="cuda")
    else:
        class DummyContext:
            def __enter__(self): return None
            def __exit__(self, exc_type, exc, tb): return False
        ctx = DummyContext()

    with ctx:
        result = pipe(
            [full_prompt] * num_images,
            negative_prompt=[negative] * num_images,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale
        )

    images = result.images
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_dir = os.path.join(output_dir, timestamp)
    ensure_dir(session_dir)

    metadata_list: List[Dict] = []

    for i, img in enumerate(images):
        # Add watermark
        img_wm = add_watermark(img, text="AI-generated by Talrn-ML-ImageGen")

        filename_base = f"img_{i+1:02d}"
        png_path = os.path.join(session_dir, filename_base + ".png")
        jpg_path = os.path.join(session_dir, filename_base + ".jpg")

        # Save PNG & JPEG
        img_wm.save(png_path, format="PNG")
        img_wm.convert("RGB").save(jpg_path, format="JPEG", quality=95)

        metadata = {
            "prompt": user_prompt,
            "full_prompt": full_prompt,
            "negative_prompt": negative,
            "style": style,
            "timestamp": timestamp,
            "num_inference_steps": num_inference_steps,
            "guidance_scale": guidance_scale,
            "paths": {
                "png": png_path,
                "jpg": jpg_path
            }
        }
        metadata_list.append(metadata)

    # Save metadata JSON
    meta_path = os.path.join(session_dir, "metadata.json")
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(metadata_list, f, indent=2)

    return metadata_list
